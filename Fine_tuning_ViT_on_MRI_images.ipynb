{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2ahKl9LrHrm"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELN-JNYDrNeQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms as T, datasets\n",
        "from transformers import ViTForImageClassification, TrainingArguments, Trainer, ViTImageProcessor\n",
        "import matplotlib.pyplot as plt\n",
        "import zipfile\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6ephZ2rrOhf"
      },
      "outputs": [],
      "source": [
        "zip_file_path = 'archive1.zip'\n",
        "extract_dir = 'brain_tumor_mri'\n",
        "\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "print(\"Files extracted to:\", extract_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8CgOmdharQer"
      },
      "outputs": [],
      "source": [
        "model_name = \"google/vit-base-patch16-224-in21k\"\n",
        "processor = ViTImageProcessor.from_pretrained(model_name)\n",
        "\n",
        "image_mean = processor.image_mean\n",
        "image_std = processor.image_std\n",
        "size = processor.size[\"height\"]\n",
        "\n",
        "\n",
        "normalize = T.Normalize(mean=image_mean, std=image_std)\n",
        "\n",
        "train_transforms = T.Compose([\n",
        "    T.RandomResizedCrop(size),\n",
        "    T.RandomHorizontalFlip(),\n",
        "    T.RandomRotation(degrees=30),\n",
        "    T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    T.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
        "    T.ToTensor(),\n",
        "    normalize\n",
        "])\n",
        "\n",
        "\n",
        "val_test_transforms = T.Compose([\n",
        "    T.Resize(size),\n",
        "    T.CenterCrop(size),\n",
        "    T.ToTensor(),\n",
        "    normalize\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gIzIsIKlKZrt"
      },
      "outputs": [],
      "source": [
        "# Load datasets\n",
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "\n",
        "train_dir = os.path.join(extract_dir, 'Training')\n",
        "test_dir = os.path.join(extract_dir, 'Testing')\n",
        "train_dataset = datasets.ImageFolder(root=train_dir, transform=train_transforms)\n",
        "test_dataset = datasets.ImageFolder(root=test_dir, transform=val_test_transforms)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=2)\n",
        "\n",
        "\n",
        "print(f'Train dataset size: {len(train_dataset)}')\n",
        "print(f'Test dataset size: {len(test_dataset)}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vp1lQ66BrU8k"
      },
      "outputs": [],
      "source": [
        "id2label = {0: 'glioma', 1: 'meningioma', 2: 'notumor', 3: 'pituitary'}\n",
        "label2id = {v: k for k, v in id2label.items()}\n",
        "\n",
        "\n",
        "model = ViTForImageClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=len(id2label),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        "    ignore_mismatched_sizes=True\n",
        ")\n",
        "\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"vit-1\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=50,\n",
        "    logging_steps=100,\n",
        "    save_total_limit=2,\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=64,\n",
        "    per_device_eval_batch_size=32,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    remove_unused_columns=False,\n",
        "    fp16=True,\n",
        "    fp16_full_eval=True,\n",
        "    dataloader_num_workers=2,\n",
        "    gradient_accumulation_steps=2,\n",
        "    push_to_hub=False,\n",
        "    logging_dir='./logs'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07i6yKsGrXHK"
      },
      "outputs": [],
      "source": [
        "def data_collator(features):\n",
        "    images, labels = zip(*features)\n",
        "    pixel_values = torch.stack(images)\n",
        "    return {'pixel_values': pixel_values, 'labels': torch.tensor(labels)}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BlsbnYeMbP6d"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = torch.argmax(torch.tensor(logits), dim=-1)\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "    return {\"accuracy\": accuracy}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3wGBM6QrYxh"
      },
      "outputs": [],
      "source": [
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "eval_results = trainer.evaluate()\n",
        "print(f\"Evaluation results: {eval_results}\")\n",
        "\n",
        "outputs = trainer.predict(test_dataset)\n",
        "print(\"Test set metrics:\")\n",
        "print(outputs.metrics)\n",
        "\n",
        "model.save_pretrained(\"vit-1\")\n",
        "processor.save_pretrained(\"vit-1\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmHn_k_praPq"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import random\n",
        "\n",
        "\n",
        "test_dir = 'brain_tumor_mri/Testing'\n",
        "num_images = 5\n",
        "\n",
        "\n",
        "test_class_dirs = os.listdir(test_dir)\n",
        "random_images = []\n",
        "\n",
        "while len(random_images) < num_images:\n",
        "    random_class = random.choice(test_class_dirs)\n",
        "    random_image_name = random.choice(os.listdir(os.path.join(test_dir, random_class)))\n",
        "    test_image_path = os.path.join(test_dir, random_class, random_image_name)\n",
        "    random_images.append((test_image_path, random_class))\n",
        "\n",
        "\n",
        "model = ViTForImageClassification.from_pretrained(\"vit-1\")\n",
        "processor = ViTImageProcessor.from_pretrained(\"vit-1\")\n",
        "\n",
        "\n",
        "fig, axs = plt.subplots(1, num_images, figsize=(20, 5))\n",
        "for i, (image_path, true_label) in enumerate(random_images):\n",
        "    test_image = Image.open(image_path).convert(\"RGB\")\n",
        "    inputs = processor(images=test_image, return_tensors=\"pt\")\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        predicted_class_id = torch.argmax(logits, dim=-1).item()\n",
        "\n",
        "    predicted_label = id2label[predicted_class_id]\n",
        "\n",
        "    axs[i].imshow(test_image)\n",
        "    axs[i].set_title(f\"True: {true_label}\\nPredicted: {predicted_label}\")\n",
        "    axs[i].axis('off')\n",
        "\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}